{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest implementation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation forest is a useful technique for Anamoly detection. \n",
    "\n",
    "The goal of this project is to implement the original Isolation Forest algorithm by Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. There are two general approaches to anomaly detection: \n",
    "\n",
    "1. Model what normal looks like and then look for nonnormal observations\n",
    "2. Focus on the anomalies, which are few and different. This is the interesting and relatively-new approach taken by the authors of isolation forests. \n",
    "\n",
    "The idea is to isolate the anomalies based on the assumption that anomalies are few and different hence they are more suspectible to isolation during random splitting as compared to normal data points. The implementation involves creating a large number of binary trees on random subsets of data split on random attributes and random values. The anomalies will on average have shorter path lengths from root. \n",
    "\n",
    "Reference: https://www.researchgate.net/publication/224384174\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T22:44:23.383098Z",
     "start_time": "2019-03-14T22:44:21.562139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from lolviz import *\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T01:52:48.117805Z",
     "start_time": "2019-03-03T01:52:48.111718Z"
    }
   },
   "outputs": [],
   "source": [
    "#Internal node\n",
    "class inNode:\n",
    "    def __init__(self,left,right,split_att,split_val):\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.split_att=split_att\n",
    "        self.split_val=split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T01:52:48.266085Z",
     "start_time": "2019-03-03T01:52:48.262832Z"
    }
   },
   "outputs": [],
   "source": [
    "#External node\n",
    "class exNode:\n",
    "    def __init__(self,size):\n",
    "        self.size=size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T01:52:48.501630Z",
     "start_time": "2019-03-03T01:52:48.495939Z"
    }
   },
   "outputs": [],
   "source": [
    "def sameCheck(X):\n",
    "    '''\n",
    "    check whether all data in a numpy array is same\n",
    "    '''\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    return np.all(X==X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating isolation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T05:58:28.958062Z",
     "start_time": "2019-03-03T05:58:28.938972Z"
    }
   },
   "outputs": [],
   "source": [
    "class IsolationTree:\n",
    "    def __init__(self, height_limit):\n",
    "        self.height_limit=height_limit\n",
    "\n",
    "    def fit(self, X:np.ndarray, improved=False):\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, create an isolation tree. Set field\n",
    "        self.root to the root of that tree and return it.\n",
    "\n",
    "        If you are working on an improved algorithm, check parameter \"improved\"\n",
    "        and switch to your new functionality else fall back on your original code.\n",
    "        \"\"\"\n",
    "        self.n_nodes=0\n",
    "        if improved:\n",
    "            self.root=self.build_faster_itree(X,0,self.height_limit)\n",
    "        else:\n",
    "            self.root=self.build_itree(X,0,self.height_limit)\n",
    "        \n",
    "        return self.root   \n",
    "    \n",
    "    \n",
    "    def build_itree(self,X,e,l):\n",
    "        #Create and return external node if current ht exceeds max ht or no more observations\n",
    "      \n",
    "        if e>=l or len(X)<=1:\n",
    "            self.n_nodes+=1\n",
    "            return exNode(len(X))\n",
    "\n",
    "        Q=X.shape[1]\n",
    "        q=np.random.randint(0,Q)\n",
    "        \n",
    "        #Create and return external node if all observations have same value for that attribute\n",
    "        att_min, att_max=X[:,q].min(),X[:,q].max()\n",
    "        if att_min==att_max:\n",
    "            self.n_nodes+=1\n",
    "            return exNode(len(X))\n",
    "        \n",
    "        p=np.random.uniform(X[:,q].min(),X[:,q].max())\n",
    "        #create a mask for splitting data on attribute value\n",
    "        mask=X[:,q]<p\n",
    "        Xl=X[mask]\n",
    "        Xr=X[~mask]\n",
    "        \n",
    "        leftTree=self.build_itree(Xl,e+1,l)\n",
    "        rightTree=self.build_itree(Xr,e+1,l)\n",
    "        self.n_nodes+=1\n",
    "        return inNode(leftTree,rightTree,q,p)\n",
    "    \n",
    "    \n",
    "    def build_faster_itree(self, X, e, l):\n",
    "\n",
    "        # Create and return external node if current ht exceeds max ht or no more observations\n",
    "        if e >= l or len(X) <= 1:\n",
    "            self.n_nodes += 1\n",
    "            return exNode(len(X))\n",
    "\n",
    "        best_split = {}\n",
    "        Q = X.shape[1]\n",
    "        smallest = len(X)\n",
    "        size = 3\n",
    "\n",
    "        # pick three random columns and three random split points for each column. Find the best split.\n",
    "        q = np.random.choice(Q, size, replace=False)\n",
    "\n",
    "        if sameCheck(X[:,q]):\n",
    "            self.n_nodes += 1\n",
    "            return exNode(len(X))\n",
    "\n",
    "        for qi in q:\n",
    "            att_min, att_max = X[:, qi].min(), X[:, qi].max()\n",
    "            if att_min == att_max: continue\n",
    "\n",
    "            p = np.random.uniform(att_min, att_max, size)\n",
    "            for pi in p:\n",
    "                mask = X[:, qi] < pi\n",
    "                Xl = X[mask]\n",
    "                Xr = X[~mask]\n",
    "                left_len = len(Xl)\n",
    "                right_len = len(Xr)\n",
    "                small = min(left_len, right_len)\n",
    "                if small < smallest:\n",
    "                    smallest = small\n",
    "                    best_split['left'] = Xl\n",
    "                    best_split['right'] = Xr\n",
    "                    best_split['split_att'] = qi\n",
    "                    best_split['split_val'] = pi\n",
    "\n",
    "\n",
    "        leftTree = self.build_itree(best_split['left'], e + 1, l)\n",
    "        rightTree = self.build_itree(best_split['right'], e + 1, l)\n",
    "        self.n_nodes += 1\n",
    "        return inNode(leftTree, rightTree, best_split['split_att'], best_split['split_val'])\n",
    "    \n",
    "  \n",
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T01:53:12.878514Z",
     "start_time": "2019-03-03T01:53:12.873539Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def H(i):\n",
    "    return np.log(i) + 0.5772156649\n",
    "\n",
    "def c(size):\n",
    "    if size==2: return 1\n",
    "    if size>2: return 2.0*(np.log(size-1)+ 0.5772156649)-(2.0*(size-1.0)/size*1.0)\n",
    "    else: return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating isolation forest and calculating average path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T01:53:13.463143Z",
     "start_time": "2019-03-03T01:53:13.446268Z"
    }
   },
   "outputs": [],
   "source": [
    "class IsolationTreeEnsemble:\n",
    "    def __init__(self, sample_size=256, n_trees=10):\n",
    "        self.sample_size=sample_size\n",
    "        self.n_trees=n_trees\n",
    "        \n",
    "\n",
    "    def fit(self, X:np.ndarray, improved=False):\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, create an ensemble of IsolationTree\n",
    "        objects and store them in a list: self.trees.  Convert DataFrames to\n",
    "        ndarray objects.\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "         \n",
    "        self.trees=[]\n",
    "        height_limit=np.ceil(np.log2(self.sample_size))\n",
    "        \n",
    "        #create t trees\n",
    "        for i in range(self.n_trees):\n",
    "            \n",
    "            itree=IsolationTree(height_limit)\n",
    "            X_sample=X[np.random.choice(X.shape[0],size=self.sample_size,replace=False)]\n",
    "            itree.root=itree.fit(X_sample,improved)\n",
    "            self.trees.append(itree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def path_length(self, X:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, X, compute the average path length\n",
    "        for each observation in X.  Compute the path length for x_i using every\n",
    "        tree in self.trees then compute the average for each x_i.  Return an\n",
    "        ndarray of shape (len(X),1).\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "            \n",
    "        path_len= np.zeros((len(X),1),dtype=float)\n",
    "        #iterate over each observation\n",
    "        for i in range(len(X)):\n",
    "            path_len_tree=[]\n",
    "            #iterate over each tree to find average path length of that observation\n",
    "            for itree in self.trees:\n",
    "                #with recursion\n",
    "                #path_len_tree.append(self.recursive_path_len(X[i],itree.root,0))\n",
    "                #without recursion (while loop)\n",
    "                path_len_tree.append(self.get_path_len(X[i],itree.root,0))\n",
    "            average_path_len=np.mean(np.array(path_len_tree))\n",
    "\n",
    "            path_len[i]=average_path_len\n",
    "        return path_len\n",
    "            \n",
    "    \n",
    "    def recursive_path_len(self,xi,node,e):\n",
    "        if isinstance(node,exNode):\n",
    "            return e+c(node.size)\n",
    "        q=node.split_att\n",
    "        if xi[q]<node.split_val : return self.recursive_path_len(xi,node.left,e+1)\n",
    "        else: return self.recursive_path_len(xi,node.right,e+1)\n",
    "        \n",
    "    def get_path_len(self,xi,node,e):\n",
    "        #stop when you reach external node\n",
    "        while isinstance(node,inNode):\n",
    "            if xi[node.split_att] < node.split_val:\n",
    "                node=node.left\n",
    "                e+=1\n",
    "            else: \n",
    "                node=node.right\n",
    "                e+=1\n",
    "        return e+c(node.size)\n",
    "            \n",
    " \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring observations based on path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def anomaly_score(self, X:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, X, compute the anomaly score\n",
    "        for each x_i observation, returning an ndarray of them.\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        path_len=self.path_length(X)\n",
    "        power= -1*path_len/c(self.sample_size)\n",
    "        anomaly_result=np.power(2,power)\n",
    "        return anomaly_result\n",
    "        \n",
    "        \n",
    "    def predict_from_anomaly_scores(self, scores:np.ndarray, threshold:float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given an array of scores and a score threshold, return an array of\n",
    "        the predictions: 1 for any score >= the threshold and 0 otherwise.\n",
    "        \"\"\"\n",
    "        predictions=scores >= threshold\n",
    "        predictions=predictions.astype(int)\n",
    "        return predictions\n",
    "        \n",
    "\n",
    "    def predict(self, X:np.ndarray, threshold:float) -> np.ndarray:\n",
    "        \"A shorthand for calling anomaly_score() and predict_from_anomaly_scores().\"\n",
    "        anomaly_result=self.anomaly_score(X)\n",
    "        predictions=self.predict_from_anomaly_scores(anomaly_result)\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a threshold for true positive rate.\n",
    "If the threshold is too high then we have low TPR and low FPR. On the other hand if the threshold is very low then we have a high TPR but also high FPR. Our objective is to have high TPR with moderately low FPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T01:53:13.659780Z",
     "start_time": "2019-03-03T01:53:13.652665Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_TPR_threshold(y, scores, desired_TPR):\n",
    "    \"\"\"\n",
    "    Start at score threshold 1.0 and work down until we hit desired TPR.\n",
    "    Step by 0.01 score increments. For each threshold, compute the TPR\n",
    "    and FPR to see if we've reached to the desired TPR. If so, return the\n",
    "    score threshold and FPR.\n",
    "    \"\"\"\n",
    "    threshold=1.01 #since first time we will deduct 0.01\n",
    "    current_TPR=0.0\n",
    "    \n",
    "    while current_TPR < desired_TPR and threshold>0:\n",
    "        #lower threshold and recalculate \n",
    "        threshold-=0.01\n",
    "        #comparing scores with threshold to get hard predictions\n",
    "        predictions = scores>=threshold\n",
    "        predictions = predictions.astype(int)\n",
    "        #calculate TPR and FPR\n",
    "        confusion = confusion_matrix(y, predictions)\n",
    "        TN, FP, FN, TP = confusion.flat\n",
    "        current_TPR = TP / (TP + FN)\n",
    "        current_FPR = FP / (FP + TN)\n",
    "        \n",
    "    return threshold,current_FPR\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation. To run the notebook choose your own dataset and extract X: features and y: labels (if available). For example see below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose hyperparameters\n",
    "1. Sample size (256 works well)\n",
    "2. Number of trees (try in range of 300-1000)\n",
    "3. Desired threshold for hard predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = IsolationTreeEnsemble(sample_size=sample_size, n_trees=n_trees)\n",
    "it.fit(X, improved=improved)\n",
    "scores = it.anomaly_score(X)\n",
    "# if true labels are available \n",
    "threshold, FPR = find_TPR_threshold(y, scores, desired_TPR)\n",
    "# if true labels are not available\n",
    "y_pred = it.predict_from_anomaly_scores(scores, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "236px",
    "left": "1082px",
    "right": "20px",
    "top": "166px",
    "width": "343px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
