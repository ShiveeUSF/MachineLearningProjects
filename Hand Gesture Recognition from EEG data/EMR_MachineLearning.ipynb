{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook we fetch the data from Mongo DB into an EMR cluster and develop several machine learning models for accurately predicting the event type from the eeg signals. \n",
    "We compare the performance of models in terms of both area under the ROC curve (AUC) and time taken to classify the test data.\n",
    "The raw EEG signals have been pre-processed and stored in Mongo DB along with their corresponding event data. The pre-processing step is part of another notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T21:35:37.748175Z",
     "start_time": "2019-03-23T21:35:37.745133Z"
    }
   },
   "outputs": [],
   "source": [
    "pyspark_submit_args = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T21:35:45.318156Z",
     "start_time": "2019-03-23T21:35:38.753497Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"myApp\") \\\n",
    ".config(\"spark.mongodb.input.uri\", \"mongodb://34.219.77.22/msds697.eeg\")\\\n",
    ".config(\"spark.executor.memory\", \"22g\")\\\n",
    ".config(\"spark.driver.memory\", \"10g\").config(\"spark.memory.offHeap.enabled\",True)\\\n",
    ".config(\"spark.memory.offHeap.size\", \"3g\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T21:35:42.125Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T21:35:43.225Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a feature vector\n",
    "target_cols = [str(x) for x in range(6)] # 6 events\n",
    "feature_cols = [str(x) for x in range(6,26)] \n",
    "\n",
    "va = VectorAssembler(outputCol=\"features\", inputCols=feature_cols)\n",
    "lpoints = va.transform(df).select(\"features\", (df['0']).alias('HandStart'),\\\n",
    "                                  (df['1']).alias('FirstDigitTouch'),\\\n",
    "                                  (df['2']).alias('BothStartLoadPhase'),\\\n",
    "                                  (df['3']).alias('LiftOff'),\\\n",
    "                                  (df['4']).alias('Replace'),\\\n",
    "                                  (df['5']).alias('BothReleased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test sets and caching them\n",
    "splits=lpoints.randomSplit([0.8,0.2])\n",
    "eeg_train = splits[0].cache()\n",
    "eeg_valid=splits[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Spark ML models to classify event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area Under ROC HandStart : 0.523186244053\n",
      "area Under ROC FirstDigitTouch : 0.564556766985\n",
      "area Under ROC BothStartLoadPhase : 0.561506486301\n",
      "area Under ROC LiftOff : 0.577604279174\n",
      "area Under ROC Replace : 0.595241467798\n",
      "area Under ROC BothReleased : 0.579037383844\n",
      "Time taken for logistic regression 150.112603903s\n"
     ]
    }
   ],
   "source": [
    "#labels are events to classify\n",
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "#iterating over the events and fitting a logisitic regression model and train it for each event\n",
    "start= time.time()\n",
    "for label in labels:\n",
    "    lr = LogisticRegression(regParam=0.01, maxIter=100, fitIntercept=True, labelCol=label)\n",
    "    lrmodel = lr.fit(eeg_train.select('features',label))\n",
    "    validpredicts = lrmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('area Under ROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for logistic regression '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area Under ROC HandStart : 0.782961545581\n",
      "area Under ROC FirstDigitTouch : 0.771348510298\n",
      "area Under ROC BothStartLoadPhase : 0.767280614945\n",
      "area Under ROC LiftOff : 0.750555491872\n",
      "area Under ROC Replace : 0.747684223274\n",
      "area Under ROC BothReleased : 0.772492734803\n",
      "Time taken for Random Forest 726.342959881s\n"
     ]
    }
   ],
   "source": [
    "#labels are events that we are trying to classify\n",
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "start= time.time()\n",
    "#iterating over the events and fitting a Random forest model and train it for each event\n",
    "for label in labels:\n",
    "    rf = RandomForestClassifier(maxDepth=10, labelCol=label)\n",
    "    rfmodel = rf.fit(eeg_train.select('features',label))\n",
    "    validpredicts = rfmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('area Under ROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for Random Forest '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC HandStart : 0.510207631536\n",
      "areaUnderROC FirstDigitTouch : 0.535821460209\n",
      "areaUnderROC BothStartLoadPhase : 0.52314056731\n",
      "areaUnderROC LiftOff : 0.525072114898\n",
      "areaUnderROC Replace : 0.554215976997\n",
      "areaUnderROC BothReleased : 0.511668626108\n",
      "Time taken for Linear SVC  4049.53015184s\n"
     ]
    }
   ],
   "source": [
    "#labels are events that we are trying to classify\n",
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "start= time.time()\n",
    "#iterating over the events and fitting a logisitic regression model and train it for each event\n",
    "for label in labels:\n",
    "    svc = LinearSVC(labelCol=label)\n",
    "    svcmodel = svc.fit(eeg_train.select('features',label))\n",
    "    validpredicts = svcmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('areaUnderROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for Linear SVC  '+ str(duration) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC HandStart : 0.856550745915\n",
      "areaUnderROC FirstDigitTouch : 0.827641404973\n",
      "areaUnderROC BothStartLoadPhase : 0.820571549804\n",
      "areaUnderROC LiftOff : 0.822932543696\n",
      "areaUnderROC Replace : 0.79483539414\n",
      "areaUnderROC BothReleased : 0.853228062129\n",
      "Time taken for Gradient Boosted Tree  939.55162406s\n"
     ]
    }
   ],
   "source": [
    "labels= ['HandStart','FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n",
    "start= time.time()\n",
    "for label in labels:\n",
    "    gbt = GBTClassifier(maxIter=10, maxDepth=10, labelCol=label)\n",
    "    gbtmodel = gbt.fit(eeg_train.select('features',label))\n",
    "    validpredicts = gbtmodel.transform(eeg_valid.select('features',label))\n",
    "    bceval = BinaryClassificationEvaluator(labelCol=label)\n",
    "    auc = bceval.evaluate(validpredicts)\n",
    "    duration= time.time()-start\n",
    "    print ('areaUnderROC ' + label+ \" : \" + str(auc))\n",
    "print('Time taken for Gradient Boosted Tree  '+ str(duration) + 's')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (694)",
   "language": "python",
   "name": "msds694"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
